{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning\n",
        "!pip install tensorboardX"
      ],
      "metadata": {
        "id": "CrjZ-Ma78a0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CmEukeg8Njd"
      },
      "outputs": [],
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as td\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "import tqdm\n",
        "import json\n",
        "import sklearn.metrics as sm\n",
        "\n",
        "import tensorboardX as tb\n",
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "np.random.seed(31337)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4cLf0zW8Njf"
      },
      "source": [
        "## Create pairs (first track, subsequent track, time)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DHUIFjU0Z09C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKlgAqq-8Njg"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"/content/drive/MyDrive/recsys-mobod-2022/seminar_05/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9aeehkP8Njh"
      },
      "outputs": [],
      "source": [
        "data = pd.read_json(DATA_DIR + \"data.json\", lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zj9JftT88Njh"
      },
      "outputs": [],
      "source": [
        "Pair = namedtuple(\"Session\", [\"user\", \"start\", \"track\", \"time\"])\n",
        "\n",
        "def get_pairs(user_data):\n",
        "    pairs = []\n",
        "    first = None\n",
        "    for _, row in user_data.sort_values(\"timestamp\").iterrows():\n",
        "        if first is None:\n",
        "            first = row[\"track\"]\n",
        "        else:\n",
        "            pairs.append(Pair(row[\"user\"], first, row[\"track\"], row[\"time\"]))\n",
        "        \n",
        "        if row[\"message\"] == \"last\":\n",
        "            first = None\n",
        "    return pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c_Ifi9_8Nji"
      },
      "outputs": [],
      "source": [
        "pairs = pd.DataFrame(\n",
        "    data\n",
        "    .groupby(\"user\")\n",
        "    .apply(get_pairs)\n",
        "    .explode()\n",
        "    .values\n",
        "    .tolist(),\n",
        "    columns=[\"user\", \"start\", \"track\", \"time\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eA0LzG3Z8Nji"
      },
      "outputs": [],
      "source": [
        "figure, ax = plt.subplots()\n",
        "sns.histplot(pairs[\"time\"], ax=ax)\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkYDflFK8Njj"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cE63YQAi8Njj"
      },
      "outputs": [],
      "source": [
        "rdm = np.random.random(len(pairs))\n",
        "train_data = pairs[rdm < 0.8]\n",
        "val_data = pairs[(rdm >= 0.8) & (rdm < 0.9)]\n",
        "test_data = pairs[rdm >= 0.9]\n",
        "\n",
        "len(train_data), len(val_data), len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head(5)"
      ],
      "metadata": {
        "id": "qevMteNvrHUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2N72w3Ym8Njl"
      },
      "outputs": [],
      "source": [
        "class ContextualRanker(pl.LightningModule):\n",
        "    def __init__(self, embedding_dim=10):\n",
        "        super().__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        \n",
        "        # We won't have embeddings for everything, but that's ok\n",
        "        self.context = nn.Embedding(num_embeddings=50000, embedding_dim=self.embedding_dim)\n",
        "        self.track = nn.Embedding(num_embeddings=50000, embedding_dim=self.embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        context = self.context(x[:, 0])\n",
        "        track = self.track(x[:, 1])\n",
        "        return torch.sum(context * track, dim=1)\n",
        "            \n",
        "    def step(self, batch, batch_idx, metric, prog_bar=False):\n",
        "        x, y = batch\n",
        "        predictions = self.forward(x)\n",
        "        loss = F.mse_loss(predictions, y.float(), reduction='mean')\n",
        "        self.log(metric, loss, prog_bar=prog_bar)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx, prog_bar=False):\n",
        "        x, y = batch\n",
        "        predictions = self.forward(x)\n",
        "        avgs = y[:, 0].float()\n",
        "        targets = y[:, 1].float()\n",
        "        rdms = y[:, 2].float()\n",
        "\n",
        "        loss = F.mse_loss(predictions, targets, reduction='mean')\n",
        "        avg_loss = F.mse_loss(avgs, targets, reduction='mean')\n",
        "        rdm_loss = F.mse_loss(rdms, targets, reduction='mean')\n",
        "\n",
        "        self.log(\"test_loss\", loss, prog_bar=prog_bar)\n",
        "        self.log(\"avg_loss\", avg_loss, prog_bar=prog_bar)\n",
        "        self.log(\"rdm_loss\", rdm_loss, prog_bar=prog_bar)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self.step(batch, batch_idx, \"train_loss\")\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self.step(batch, batch_idx, \"val_loss\", True)\n",
        "        \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
        "        scheduler = {\n",
        "            'scheduler': lr_scheduler,\n",
        "            'reduce_on_plateau': True,\n",
        "            'monitor': 'val_loss'\n",
        "        }\n",
        "        return [optimizer], [scheduler]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ContextualRankerData(pl.LightningDataModule):\n",
        "  def __init__(self, train_data, val_data, test_data, features):\n",
        "      super().__init__()\n",
        "      self.train_data = train_data\n",
        "      self.val_data = val_data\n",
        "      self.test_data = test_data\n",
        "      self.features = features\n",
        "\n",
        "  def prepare_data(self):\n",
        "      self.test_data = self.test_data.assign(rdm = np.random.random(len(self.test_data))).assign(avg = self.train_data[\"time\"].mean())\n",
        "\n",
        "  def setup(self, stage=None):\n",
        "      if stage == \"fit\" or stage is None:\n",
        "        self.train_dataset = td.TensorDataset(\n",
        "            torch.from_numpy(self.train_data[self.features].values), \n",
        "            torch.from_numpy(self.train_data[\"time\"].values)\n",
        "            )\n",
        "\n",
        "        self.val_dataset = td.TensorDataset(\n",
        "            torch.from_numpy(self.val_data[self.features].values), \n",
        "            torch.from_numpy(self.val_data[\"time\"].values)\n",
        "            )\n",
        "        \n",
        "      if stage == \"test\" or stage is None:  \n",
        "        self.test_dataset = td.TensorDataset(\n",
        "            torch.from_numpy(self.test_data[self.features].values),\n",
        "            torch.from_numpy(self.test_data[[\"time\", \"avg\", \"rdm\"]].values)\n",
        "        )\n",
        "  def train_dataloader(self):\n",
        "      return td.DataLoader(self.train_dataset, batch_size=2048, shuffle=True, num_workers=0)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "      return td.DataLoader(self.val_dataset, batch_size=2048, num_workers=0)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "      return td.DataLoader(self.test_dataset, batch_size=512, shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "id": "XSZTEW7h9d3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWZ8cqTZ8Njm"
      },
      "outputs": [],
      "source": [
        "net = ContextualRanker(embedding_dim=100)\n",
        "data_module = ContextualRankerData(train_data, val_data, test_data, features = [\"start\", \"track\"])\n",
        "\n",
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor=\"val_loss\")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=300,\n",
        "    accelerator='gpu', \n",
        "    devices=1,\n",
        "    callbacks=[\n",
        "        pl.callbacks.early_stopping.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
        "        pl.callbacks.LearningRateMonitor(logging_interval=\"step\"),\n",
        "        checkpoint_callback\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/lightning_logs --host localhost"
      ],
      "metadata": {
        "id": "omCmoxVhGfJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sqy8qDr98Njm"
      },
      "outputs": [],
      "source": [
        "trainer.fit(\n",
        "    net, \n",
        "    data_module\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IeB7jzb8Njn"
      },
      "outputs": [],
      "source": [
        "best = ContextualRanker.load_from_checkpoint(checkpoint_callback.best_model_path, embedding_dim=100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(best, data_module)"
      ],
      "metadata": {
        "id": "HTUgc8_hQ7N0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRZLUR9_8Njo"
      },
      "source": [
        "## Compute top recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UrLSjgt8Njo"
      },
      "outputs": [],
      "source": [
        "track_meta = pd.read_json(DATA_DIR + \"tracks.json\", lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqwVsVyO8Njp"
      },
      "outputs": [],
      "source": [
        "context_embeddings = dict(best.named_parameters())[\"context.weight\"].data.cpu().numpy()\n",
        "track_embeddings = dict(best.named_parameters())[\"track.weight\"].data.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-z1VTPGh8Njp"
      },
      "outputs": [],
      "source": [
        "track_meta.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7_A20no8Njp"
      },
      "outputs": [],
      "source": [
        "k = 100\n",
        "with open(DATA_DIR + \"tracks_with_recs.json\", \"w\") as rf:\n",
        "    for _, track in tqdm.tqdm(track_meta.iterrows()):\n",
        "        embedding = context_embeddings[track[\"track\"]]\n",
        "        neighbours = np.argpartition(-np.dot(track_embeddings, embedding), k)[:k]\n",
        "        \n",
        "        recommendation = dict(track)\n",
        "        recommendation[\"recommendations\"] = neighbours.tolist()\n",
        "        \n",
        "        rf.write(json.dumps(recommendation) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhS_o_ff8Njp"
      },
      "outputs": [],
      "source": [
        "track = 3916\n",
        "embedding = context_embeddings[track]\n",
        "track_meta.loc[track_meta[\"track\"] == track, [\"artist\", \"title\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGFHEN8g8Njq"
      },
      "outputs": [],
      "source": [
        "k = 10\n",
        "neighbours = np.argpartition(-np.dot(track_embeddings, embedding), k)[:k]\n",
        "track_meta.loc[track_meta[\"track\"].isin(neighbours), [\"artist\", \"title\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymCblQht8Njq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv_made_2022",
      "language": "python",
      "name": "venv_made_2022"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
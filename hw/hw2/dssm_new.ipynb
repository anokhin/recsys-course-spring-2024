{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PBWLwwIJfk9v"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as td\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "import json\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorboardX as tb\n",
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import typing as tp\n",
    "import faiss\n",
    "import glob\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from functools import partial\n",
    "import shutil\n",
    "\n",
    "np.random.seed(31337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8g9i8tgrfmM9"
   },
   "outputs": [],
   "source": [
    "data = pd.concat([\n",
    "        pd.read_json(data_path, lines=True) \n",
    "        for data_path \n",
    "        in glob.glob(\"./data/*/data.json\")\n",
    "    ] + [pd.read_csv(\"./data/contextual_data.csv\")])\n",
    "\n",
    "data = data[[\"message\", \"timestamp\", \"user\", \"track\", \"time\"]]\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"])\n",
    "track_metadata = pd.read_json(\"data/tracks.json\", lines=True).drop_duplicates(subset=[\"track\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lA1Ba7eC3_Cj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(813355, 149852, 11149)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives = data[data[\"time\"] > 0.8].copy()\n",
    "negatives = data[(data[\"time\"] > 0.1) * (data[\"time\"] < 0.3)].copy()\n",
    "\n",
    "track_counts = positives.groupby(\"track\").size()\n",
    "tracks = set(track_counts[track_counts >= 20].index.values)\n",
    "\n",
    "pos_data_filt = positives[positives[\"track\"].isin(tracks)]\n",
    "neg_data_filt = negatives[negatives[\"track\"].isin(tracks)]\n",
    "\n",
    "len(pos_data_filt), len(neg_data_filt), len(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZIJNR8jThuKi"
   },
   "outputs": [],
   "source": [
    "track_metadata = track_metadata.fillna(value={'genre': 'Unk'})\n",
    "track_metadata[\"genre\"] = LabelEncoder().fit_transform(track_metadata[\"genre\"])\n",
    "track_metadata[\"artist\"] = LabelEncoder().fit_transform(track_metadata[\"artist\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aWpRk9DJhx1A"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features = track_metadata[[\"track\", \"genre\", \"artist\", \"pop\"]].set_index(\"track\", drop=False)\n",
    "item_features['pop'] = np.log(item_features['pop'])\n",
    "item_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_number = len(np.unique(item_features[\"genre\"]))\n",
    "artist_number = len(np.unique(item_features[\"artist\"]))\n",
    "track_number = 50000\n",
    "user_number = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "L6bKkHN5JtUH"
   },
   "outputs": [],
   "source": [
    "triplets = pos_data_filt[[\"user\", \"track\"]].rename(columns={\"track\": \"track_pos\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Q8nMB0TSyKFf"
   },
   "outputs": [],
   "source": [
    "NUM_NEGATIVE_SAMPLES = 15\n",
    "triplets =  pd.concat([triplets] * NUM_NEGATIVE_SAMPLES).sort_index().reset_index(drop=True)\n",
    "triplets[\"track_neg\"] = np.random.choice(range(50000), len(triplets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Qb2n71PAbwHK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9760693, 1219922, 1219710)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdm = np.random.random(len(triplets))\n",
    "train_data = triplets[rdm < 0.8]\n",
    "val_data = triplets[(rdm >= 0.8) & (rdm < 0.9)]\n",
    "test_data = triplets[rdm >= 0.9]\n",
    "\n",
    "len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "djkimxU8E_tg"
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def pad_with_specific_value(lst, size, val):\n",
    "    lst = list(set(lst))\n",
    "    shuffle(lst)\n",
    "    lst = lst[:size]\n",
    "    return np.pad(lst, (0, size - len(lst)), 'constant', constant_values=(val))\n",
    "\n",
    "pos_padded_users = triplets.groupby(\"user\").apply(lambda x: (\n",
    "    pad_with_specific_value(x['track_pos'].tolist(), 30, 50000).tolist()\n",
    "))\n",
    "neg_padded_users = negatives.groupby(\"user\").apply(lambda x: (\n",
    "    pad_with_specific_value(x['track'].tolist(), 30, 50000).tolist()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "8qajx2uohDqL"
   },
   "outputs": [],
   "source": [
    "pos_padded_users = pos_padded_users.reindex(np.arange(user_number), fill_value=[50000] * 30)\n",
    "neg_padded_users = neg_padded_users.reindex(np.arange(user_number), fill_value=[50000] * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "o2GL8vu_Gvl3"
   },
   "outputs": [],
   "source": [
    "class DSSMData(pl.LightningDataModule):\n",
    "    def __init__(self, train_triplets, val_triplets, test_triplets, item_features, pos_padded_users, neg_padded_users):\n",
    "        super().__init__()\n",
    "        self.train_triplets = train_triplets\n",
    "        self.val_triplets = val_triplets\n",
    "        self.test_triplets = test_triplets\n",
    "        self.item_features = item_features\n",
    "        self.pos_padded_users = pos_padded_users\n",
    "        self.neg_padded_users = neg_padded_users\n",
    "        self.fit_prepared = False\n",
    "\n",
    "    def _collect_data(self, triplets):\n",
    "        users = triplets[\"user\"].values\n",
    "        positives = triplets[\"track_pos\"].values\n",
    "        negatives = triplets[\"track_neg\"].values\n",
    "\n",
    "        print(\"collecting liked\")\n",
    "        liked_tracks = self.pos_padded_users[users]\n",
    "        liked_tracks = np.stack(liked_tracks.values)\n",
    "        liked_tracks[liked_tracks == positives.reshape(-1, 1)] = 50000\n",
    "        liked_tracks[liked_tracks == negatives.reshape(-1, 1)] = 50000\n",
    "        \n",
    "        print(\"collecting disliked\")\n",
    "        disliked_tracks = self.neg_padded_users[users]\n",
    "        disliked_tracks = np.stack(disliked_tracks.values)\n",
    "        disliked_tracks[disliked_tracks == positives.reshape(-1, 1)] = 50000\n",
    "        disliked_tracks[disliked_tracks == negatives.reshape(-1, 1)] = 50000\n",
    "\n",
    "        return td.TensorDataset(\n",
    "            torch.from_numpy(liked_tracks).long(),\n",
    "            torch.from_numpy(disliked_tracks).long(),\n",
    "            torch.from_numpy(item_features.loc[positives].values).long(),\n",
    "            torch.from_numpy(item_features.loc[negatives].values).long(),\n",
    "        )\n",
    "\n",
    "    def prepare_data(self, stage=None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            if self.fit_prepared:\n",
    "                return\n",
    "            self.train_dataset = self._collect_data(self.train_triplets)\n",
    "            self.val_dataset = self._collect_data(self.val_triplets)\n",
    "            self.fit_prepared = True\n",
    "        elif stage == \"test\" or stage is None:\n",
    "            self.test_dataset = self._collect_data(self.test_triplets)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return td.DataLoader(self.train_dataset, batch_size=1024, shuffle=True, num_workers=0)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return td.DataLoader(self.val_dataset, batch_size=1024, num_workers=0)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return td.DataLoader(self.test_dataset, batch_size=1024, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ao7sknxb_t1t"
   },
   "source": [
    "### DSSM-модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "LtKX8AVoc18i"
   },
   "outputs": [],
   "source": [
    "class DSSM(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        genres: int,\n",
    "        artists: int,\n",
    "        item_number: int,\n",
    "        embedding_dim: int = 100,\n",
    "        activation: tp.Callable[[torch.Tensor], torch.Tensor] = F.relu,\n",
    "        lr: float = 1e-3,\n",
    "        triplet_loss_margin: float = 0.4,\n",
    "        weight_decay: float = 1e-6,\n",
    "        log_to_prog_bar: bool = True,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.triplet_loss_margin = triplet_loss_margin\n",
    "        self.weight_decay = weight_decay\n",
    "        self.log_to_prog_bar = log_to_prog_bar\n",
    "        self.item_net = ItemNet(embedding_dim, genres, artists, activation)\n",
    "        self.user_net = UserNet(embedding_dim, item_number)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        liked_tracks: torch.Tensor,\n",
    "        disliked_tracks: torch.Tensor,\n",
    "        item_features_pos: torch.Tensor,\n",
    "        item_features_neg: torch.Tensor,\n",
    "    ) -> tp.Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        anchor = self.user_net(liked_tracks, disliked_tracks)\n",
    "        pos = self.item_net(item_features_pos)\n",
    "        neg = self.item_net(item_features_neg)\n",
    "        return anchor, pos, neg\n",
    "\n",
    "    def _step(self, batch, batch_idx, metric, prog_bar=False):\n",
    "        liked_tracks, disliked_tracks, pos, neg = batch\n",
    "        anchor, positive, negative = self(liked_tracks, disliked_tracks, pos, neg)\n",
    "        loss = F.triplet_margin_loss(anchor, positive, negative, margin=self.triplet_loss_margin)\n",
    "        self.log(metric, loss, prog_bar=prog_bar)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch: tp.Sequence[torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        return self._step(batch, batch_idx, \"train_loss\")\n",
    "\n",
    "    def validation_step(self, batch: tp.Sequence[torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        return self._step(batch, batch_idx, \"val_loss\", self.log_to_prog_bar)\n",
    "\n",
    "    def test_step(self, batch, batch_idx, prog_bar=False):\n",
    "        return self._step(batch, batch_idx, \"test_loss\", self.log_to_prog_bar)\n",
    "\n",
    "    def inference(self, dataloader: td.DataLoader[tp.Any], mode: str = \"item\") -> np.ndarray:\n",
    "        batches = []\n",
    "        user_ids = []\n",
    "        if(mode == \"user\"):\n",
    "            model = self.user_net\n",
    "        elif(mode == \"item\"):\n",
    "            model = self.item_net\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model {mode}!\")\n",
    "\n",
    "        self.eval()\n",
    "        for batch in dataloader:\n",
    "            ids, features = batch\n",
    "            with torch.no_grad():\n",
    "                v_batch = model(features.to(self.device))\n",
    "            batches.append(v_batch)\n",
    "            user_ids.append(ids)\n",
    "        vectors = torch.cat(batches, dim=0).cpu().numpy()\n",
    "        vectors_ids = torch.cat(user_ids, dim=0).cpu().numpy()\n",
    "        return vectors_ids, vectors\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
    "        scheduler = {\n",
    "            'scheduler': lr_scheduler,\n",
    "            'monitor': 'val_loss'\n",
    "        }\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "6h5-80IAjYA6"
   },
   "outputs": [],
   "source": [
    "class ItemNet(nn.Module):\n",
    "    def __init__(self, n_factors: int, genres, artists, activation: tp.Callable[[torch.Tensor], torch.Tensor] = F.relu) -> None:\n",
    "        super().__init__()\n",
    "        self.genre_embedding_layer = nn.Embedding(genres+1, n_factors)\n",
    "        self.artist_embedding_layer = nn.Embedding(artists+1, n_factors)\n",
    "        self.dense_layer = nn.Linear(n_factors + 1, n_factors, bias=False)\n",
    "        self.output_layer = nn.Linear(n_factors * 2, n_factors, bias=False)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, item_features: torch.Tensor) -> torch.Tensor:\n",
    "        popularity = item_features[:, 3].view(-1, 1)\n",
    "        emb = self.genre_embedding_layer(item_features[:, 1])\n",
    "        emb += self.artist_embedding_layer(item_features[:,2])\n",
    "\n",
    "        pop_emb = torch.concat([popularity, emb], axis=1)\n",
    "        features = self.activation(self.dense_layer(pop_emb))\n",
    "\n",
    "        emb_features = torch.concat([emb, features], axis=1)\n",
    "        output = self.output_layer(emb_features)\n",
    "        return output\n",
    "\n",
    "class UserNet(nn.Module):\n",
    "    def __init__(self, n_factors: int, num_embeddings: int, activation: tp.Callable[[torch.Tensor], torch.Tensor] = F.relu) -> None:\n",
    "        super().__init__()\n",
    "        self.track_embeddings = nn.EmbeddingBag(num_embeddings+1, n_factors, padding_idx=num_embeddings)\n",
    "        self.dense_layer = nn.Linear(n_factors, n_factors, bias=False)\n",
    "        self.output_layer = nn.Linear(n_factors + n_factors, n_factors, bias=False)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, liked_tracks, disliked_tracks) -> torch.Tensor:\n",
    "        interactions_emb = self.track_embeddings(liked_tracks)\n",
    "        interactions_emb -= self.track_embeddings(disliked_tracks)\n",
    "        features = self.activation(self.dense_layer(interactions_emb))\n",
    "        x = torch.concat([interactions_emb, features], axis=1)\n",
    "        output = self.output_layer(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = DSSMData(train_data, val_data, test_data, item_features, pos_padded_users, neg_padded_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DSSM(genre_number, artist_number, item_number=50000, embedding_dim=64).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "b3XKIDk6Phrw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=\"./data/checkpoints/dssm2/\", monitor=\"val_loss\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    accelerator='gpu',\n",
    "    devices=1,\n",
    "    callbacks=[\n",
    "        pl.callbacks.early_stopping.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "        pl.callbacks.LearningRateMonitor(logging_interval=\"step\"),\n",
    "        checkpoint_callback,\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "uLVE_fA-iuxR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type    | Params\n",
      "-------------------------------------\n",
      "0 | item_net | ItemNet | 801 K \n",
      "1 | user_net | UserNet | 3.2 M \n",
      "-------------------------------------\n",
      "4.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 M     Total params\n",
      "16.056    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a054c2ec95d44259dafc999a9e4a3f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    net,\n",
    "    data_module\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = DSSM.load_from_checkpoint(checkpoint_callback.best_model_path, genres=genre_number, artists=artist_number, item_number=50000, embedding_dim=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "best = best.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    item_embeds = best.item_net(torch.from_numpy(item_features.values).long().to(device)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_res = faiss.StandardGpuResources()\n",
    "index = faiss.index_factory(64, \"Flat\", faiss.METRIC_L2)\n",
    "index = faiss.index_cpu_to_gpu(gpu_res, 0, index)\n",
    "\n",
    "index.add(item_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppu = torch.from_numpy(np.stack(pos_padded_users))\n",
    "npu = torch.from_numpy(np.stack(neg_padded_users))\n",
    "user_ds = td.TensorDataset(ppu, npu)\n",
    "user_dl = td.DataLoader(user_ds, batch_size=512, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = []\n",
    "for batch in user_dl:\n",
    "    ppu, npu = batch\n",
    "    with torch.no_grad():\n",
    "        v_batch = best.user_net(ppu.to(best.device), npu.to(best.device))\n",
    "    batches.append(v_batch.cpu())\n",
    "user_embs = torch.cat(batches, dim=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, tracks = index.search(user_embs, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74ad3b00596423b8712c0ba30fe5d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(f\"../../botify/data/recommendations_dssm_new.json\", \"w\") as rf:\n",
    "    for user in tqdm(range(user_number)):\n",
    "        recommendation = {\n",
    "            \"user\": int(user),\n",
    "            \"tracks\": tracks[user,:].tolist()\n",
    "        }\n",
    "        rf.write(json.dumps(recommendation) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
